10th Nov 2023
Git

Docker

Kubernetes

Jenkins

Sonarqube

AWS Certification
1.CCP(cloud practitioner)
2.Developer associate(ECS,EC2,EKS,AwsPipeline)
3.Solution Architech associate(All AWS services)

AWS:- Application
1 Iaas(Infrastructure as a service) EC2(virtual server), Install Required Softwares, Manage Patches, Deploy Application

2 Pass(Platform as a service) ElasticBeanStalk War/jar
Note: We don't have to worry about managing the underlying infrastructure in Paas

3 Docker DockerImage -> containers in the cloud
  We can store docker images in hub.docker.com or a service available in aws is ECR:- Elastic Container Registry

  To run the containers in the cloud, we have a service in aws which is ECS:- Elastic Container Service
	If we want to manage everything on our own, we have something like ECS with EC2 instances or ECS with Fargate(Serverless) not in free tier

  If we have to manage kubernetes clusters and all, we have one more flavor which is EKS:- Elastic Kubernetes Service not in free tier

Jenkins(It acts a continuous integration server)
	What is CI/CD? (Continuous Integration / Continuous Delivery)
	Install Jenkins (CI Server)

	Take an example, we have one developed application with source code and creating a artifact(jar/war/ear) from it and we deploy that
	artifact on the server. Once it is deployed, end user is going to access the application. End user(client) have found some functional
	fault in the application and raised a ticket in JIRA. The ticket is assigned to one developer and developer found the issue in the
	code and resolved it. Developer won't keep the resolved issue with him/her and creates a new artifact and the new artifact has to be
	deployed on the server again. Whenever the developer deploy the new artifact, meanwhile the application will be (or) may be down. And
	again end user found some issues in the application, lets take some 100 issues and for 100 issues should the developer deploy the
	100 resolved issues 100 times? In this scenario we need CI/CD tool. Once the developer commit his/her changes on any VCS, the build
	(jar/war/ear) has to be automatically generated and it has to be deployed on the server automatically(No Manual Intervention).

Build Tools(is also known as Project Manangement Tool which helps in creating artifacts for the application)for java
	Ant / Maven(configuration is in xml like pom.xml) / Graddle(no xml at all)
	Once the artifact is generated
	
	In DockerFile,
	FROM baseImage
	COPY .war to
	ENTRYPOINT

	Docker Image

To deploy the backend part of the application, we launch a virtual server with the service EC2 then install java and run the application with
the cmd 'java -jar myapp.jar'

for .net

for angular -> we make use of the cmd 'ng build'

for react -> we make use of the cmd 'ng build'

To deploy angular or react application on aws, we have aws cloud service which is S3(Simple Storage Service) Object Storage

DockerFile for frontend part

Docker Image

Now we have two containers, front end and back end

Container communication

					AWS CodePipeline
AWS CodeCommit(GitRepository) -> Code Build(JAR,WAR,EAR) -> Code Deploy ECS
												EC2

Without writing the dockerfile for your application, the dockerimage still getting created that is through plugins().

20th Nov 2023
Application XYZ deployed in company premises(On Prem Deployment)

EC2(Elastic Compute Cloud) lets us to create virtual server(we have manage the server which is not serverless)

Serverless AWS Lambda(we don't have to manage the server)

For RDS(Relational Database Service), we have MySQL, Oracle, PostgresSQL, Amazon Aurora

Fon NRDS(Non-Relational Database Service), we have DynamoDB and for cloud we have a service 'DocumentDB' like MongoDB Workload

Logged into https://aws.amazon.com/console/ and explored on variety of categories and services

In one region we may have 3 or more AZ's(Availability Zones which means Data Center)

Why we have to go for region and AZ's?
Suppose we have developed one application and deployed. Most of the users of the application are in India and the developer is in N.Virginia. So, developer will be
deploying the application either in mumbai region or in hyderabad region in one AZ. If the AZ goes down, we may face the application downtime. Instead we can deploy
the application in multiple AZ's which are connected with low latency network provided by AWS.

We have a service in aws 'DR(Disaster Recovery) Strategies'

EC2 is a Regional Service because we are creating a virtual server where the end users are mostly available
S3 is a Global Service -> In S3, we will create a bucket which means a region

All the services are not available in all the regions all the time. There might be a possibility there is a service which is there in a particular region only.

While selecting a region, we have to include some factors like no. of end users, regional costs, data security etc.,

AMI(Amazon Machine Image)
Select an AMI which is free tier eligible
There will be a cost vary in selecting different regions while selecting an AMI

Key Pair: If we want to connect to virtual server through our laptop, we require key pair.

VPC(Virtual Private Cloud)

Root Volume is a volume where the OS resides

ASG(Auto Scaling Group)

22nd Nov 2023
I have started my instance named 'ForDocker' and I have
public IP: 43.204.96.91
private IP: 172.31.11.70
and stopped the instance
Again I have started the same instance and I have
public IP: 13.233.137.211
private IP: 172.31.11.70
and we will get new public IP address and private remains the same

With ElasticIP service, we can achieve to have the same public IP address even when we restart the instance(virtual server)

On the left sidebar of aws EC2 dashboard, go to the option 'Elastic IPs' and click on 'Allocate Elastic IP address' and create one

After creation of elastic IP address, select it and under actions dropdown select 'Associate Elastic IP Address'. Select 'Instance' as resource type and choose for
which instance you want to associate and then click on 'Associate' button.

Now stop and restart the instance, we will have the same public IP address

We have to pay the charges if we have created any elastic IP address and have not associated to any instances

To prevent the charges for elastic IP address, we first have to 'Disassociate elastic IP address' if it associating any instances which is an option available under
actions and also have to relase or delete it by selecting the option 'Release elastic IP addresses' under actions.

To connect with the EC2 instance, select the instance to which you wanted to connect with and click on 'Connect' button. Go with an option 'Connect using EC2 Instance
Connect' and click on 'Connect' button which opens a new tab connect to that instance.

Another way of connecting to EC2 instance is we have an option 'SSH client' and copy 'ssh -i "fordocker.pem" ec2-user@ec2-52-66-255-77.ap-south-1.compute.amazonaws.com'
in powershell where the keypair resides and run. If we get any error, try to run the cmd 'chmod 0600 keypairname.pem'.

Other way is by loading the keypair.pem file in PuttyGen software and generate the key and save it as public key or private key(in ppk format). Then open Putty software,
copy the public IPv4 DNS and paste it under Host Name in putty software(by default the port will be 22) and also for auth under ssh, select the saved key and clik on
open.

The last way to connect with the EC2 instance is with the software named 'mobaxterm'.

After connecting to the instance, executed some cmds like whoami, pwd, ls.

To switch to root user, we use the cmd 'sudo su'

Installed the web server as the root user with the cmd 'yum install httpd'

To start the web server service, we use the cmd 'systemctl start httpd'

To enable the web server service, we use the cmd 'systemctl enable httpd'

To stop the web server service, we use the cmd 'systemctl stop httpd'

To disable the web server service, we use the cmd 'systemctl disable httpd'

To know the status of the web server service, we use the cmd 'systemctl status httpd'

To access the web server, copy the public IPv4 address and paste it in any browser and add a inbound security rule in security groups page with
'HTTP' as a type and 'IPv4' as IP version and save the rules. Reload the page in the browser with the public IPv4 address which displays 'It works!'.
We have to allow the traffic from 'http'.

We have 2 rules in security group: Inbound and Outbound

Security group is stateful. If we have the inbound traffic for http then automatically we get the outbound for the same. We dont have to explicitly
specify the outbound rule.

NACL(Network Access Control List)

In case of Iaas, we have to install the OS, required softwares, and we have our application

In case of Paas(Elastic Beanstalk), we don't have to install the OS, required softwares but just deploying our application on top of it

In case of Saas, we even don't have to worry about installing the application on top of the platform

We can also have windows as AMI and to connect with it, we can use the RDP client and get password by uploading keypair.pem file and decrypt it
which downloads .rdp file and we have to run it which asks us to enter the decrypted password.

We can also create our own AMI like windows with 10 softwares and creating an image from it and using it by creating an instance.

24th Nov 2023
At the time of launching the instance, if we want to do installation of software we can make use of 'user data'. We will have advanced details section while creating
the instance where we find the option 'user data - optional'. Have the below code in the 'user data' textarea which is a shell script:
#!/bin/bash
# Use this for your user data(script from top to bottom)
# install httpd (Linux 2 version)
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
echo "<h1>Hello Abhijith from $(hostname -f)</h1>" > /var/www/html/index.html

I have launched a new instance naming 'Phase3WithShellScriptCode' by adding user data into it and accessed it in the browser with the public IPv4
address with port no. 80.

Suppose we have launched another instance with some user data and it will not have same public IPv4 address like the above one we have launched.
In both the instances, we have our deployed application. And the users won't know both the public IPv4 addresses to access the application. So,
we make use of 'Load Balancer(LB)' here where we register our two instances and distribute the load equally on both the instances. If any instance
fails, LB won't forward the request to failed instance rather it will forward the request to the healthy(successfully running) instance.

Types of LB
-> Application LB(Layer 7)
-> Network LB(Layer 4)
-> Classical LB(Layer 7 and Layer 4)
-> Gateway LB(GENEVE)

Took Screenshot(pic7) of the image explanation on how to redirect requests from user if we have multiple instances for our application by creating a
load balancer(MyALP) where we have our running instances in the target group(MyTargetGroup).

Created a load balancer(MyALP) to redirect requests from user if we have multiple instances for our application and a target group(MyTargetGroup)
which groups the running instances where we have our deployed application. And also created a new security group(MySecurityGrp) and assigned it
to two running instances.

Volume Types:
1. Root Volume 8gb where OS resides
2. EBS(Elastic Block Storage) Volume 5gb
Suppose we have created a new volume(not a root volume) of 3gb from volumes dashboard and we can attach it to the existing instance from volumes
dashboard. We must create the volume based on the instance availability zone.
If we want to deleted the instance which have 8gb root volume, 5gb EBS volume and added 3gb volume, along with instance the allocated root volume
will be deleted.
If we don't want the root volume to be deleted while deleting the EC2 instance, we have to change the value of delete on termination to 'No' under
advanced settings of volume creation while creating an instance. 
Note:
-> We can attach one instance EBS volume to another instance with the help of multi attach EBS Volume that to only for some selected
instances(nitro instances, May ask the question in Solution Architech Exam and not in Cloud practitioner Exam)
-> If we won't make use of the volume which is in Available state, we have to pay charges.(Delete them if not necessary)
-> Even if the EC2 instance is in stopped state, we don't have to pay any chares but we have pay the cost for the volume associated to it.

27th Nov 2023
If we have created a volume in ap-south-1b zone, we won't be able to use in zone ap-south-1a. Then, we have to take snapshot of volume which is
in ap-south-1b and store the snapshot in zone ap-south-1a. From the stored snapshot, we can create another volume in zone ap-south-1a.

If we have created a volume and attach the volume directly to the instance is known as Instance Store. Instance Store will act like a cache where
we will have the data till the time the instance is up and running. The advantage is we will get the data much faster than EBS volumes but the
disadvantage is we lost the data once the instance is down.

If we want to share the data which is in EBS volume to 3 EC2 instances, EBS volume is not the best choice to share data cross 3 EC2 instances. To
overcome this issue, we have a service known as EFS(Elastic File Store) which is a network file share.

We also have another storage service which is S3(Simple Storage Service). We always deal with object in S3 service. We store objects in bucket
(container of objects). We can't have object without bucket. S3 is a global service. But within while creating a bucket, we have specify a region
like ap-south-1a or ap-south-1b. We have to give unique bucket name because aws checks across all aws accounts bucket names and if we give
already existing bucket name, it will throw an error. In aws terminology, we call bucket for folders, objects for any items like audio, image,
video.

I have created a bucket naming 'mybucket14jan2024' and uploaded a pdf file by clicking on 'Add Files' button with a storage class 'Standard'
under properties tab. After uploading, if we try to access it from AWS S3 bucket, we will get an 'access denied' page because while creating
bucket we chose 'Block publice access settings for this bucket' option.

In my bucket, i may have 10 objects but i don't want to have access to all 10 objects but some of them. We can do it by configuring the policy
under 'permissions' tab inside the bucket. Uncheck the 'Block all public access' in the permissions tab inside the bucket. We have to click on
Bucket Policy tab 'Edit' button and go to 'Policy generator' link. There select 'S3 Bucket Policy' as Type of policy, 'Allow' as Effect, '*' as
Principal, 'Get Object' as Actions, Copy and paste ARN no., then click on 'Add Statement' button and then 'Generate Policy' button. Copy the
generated policy which is in json format and paste it in Bucket policy textarea and save the changes. Then open the object with the Object URL.
(1:26:00)

IAM
To give access to your aws console, we shouldn't provide the root user credentials. Instead, make use of IAM(Identity and Access Management)
user and give access. We can create a IAM user by going to IAM services from AWS.

Through root user, i have created one IAM user naming 'tom' and pwd is 'Killi@12345' and by default this IAM user doesn't have any permissions
like EC2 instance creation, bucket creation etc., While logging in as IAM user 'tom', enter the account id 459165937935.

We may get an API errors if we got to EC2 dashboard at first when we login as IAM user 'tom' because he doesn't have any permissions. To give
permissions, login with root user, go to IAM users dashboard and add permissions like 'AdministratorAccess'. And again login as the IAM user
'tom' and then we won't get any API errors.

We can create user groups for different positions like for example developer, project manager, etc., and the access to the resources(policy users)
of the AWS will be proivided to the new employee or new project member based on the position. A user can be a part of multiple user groups. Multiple
user groups can have mulitple policies attached.

Suppose we have two services like EC2 and S3 and we want to have communication between the services then we can make use of Role(s) in IAM.

29th Nov 2023
Elastic Beanstalk(Paas)
In case of Iaas, we have to pay the cost because we have to keep running the EC2 instance where we have deployed our application to make available
to the end users.
In case of Paas, we get the platform by-default and we only have to deploy our application.
Q. What is Elastic Beanstalk?
A. We can run and manage web apps.

Elastic Beanstalk Service is free but whatever resources we use to run our application is chargeable.

Created an web application using Elastic Beanstalk platform naming 'my-app' with java. We only have to select what are the software requirements
to deploy our application where the Elastic Beanstalk platform will install the specified softwares. Once the environment is ready, copy the Domain
url and open it in the browser which displays the message like 'Congratulations Your first AWS Elastic Beanstalk Corretto application is now running
on your own dedicated environment in the AWS CloudThis environment is launched with Elastic Beanstalk Corretto Platform'.

Still we have to pay for virtual servers (EC2 Instances) in Elastic Beanstalk, so we have another service like Serverless Model which we don't have
to manage the servers by our own. The serverless service will be available with AWS Lambda.
I have created a serverless function through Lambda Service naming 'my-lambda-function'. After creation of a function, we have to create a test
event and then run the test event. We can make changes 'index.mjs' file and deploy it and then click on Test button to display the response. We
dont't have pay for creation of a function but we have to pay when execute the program and the time took for the execution.

To run the containers in the AWS cloud, we have ECS(Elastic Container Service). We have two flavors of ECS:
-> ECS with EC2 instances
-> ECS with Fargate
We can get the images from Docker Hub (or) Elastic Container Registry(ECR)

EKS(Elastic Kubernetes Service)

Types of instances
1. On-Demand Instances - cost is so high
2. Reserved Instances - we have to commit for 1,3 years to aws services(upfront, partial upfront, no upfront). We get EC2 instances with discounts.
3. Spot Instances - We will get around 90% discount. But the disadvantage is that the EC2 instance will be terminated by AWS by providing the 2 minutes
warning. We can't run business critical applications.
Example for all types of instances:
1. Planning a trip XXX room On Demand 3000(For On-Demand Instance)
2. Booked the room before 3-6 months (For Reserved Instance payment may be upfront, partial upfront, no upfront) 
3. Book 1 room with 1500 but have to leave if another customer makes payment more than 1500(For Spot Instance)

Containers in the cloud(ECR, ECS)